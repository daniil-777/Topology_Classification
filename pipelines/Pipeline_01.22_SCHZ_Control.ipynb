{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "%pylab inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, StratifiedShuffleSplit, cross_val_score, cross_val_predict, GridSearchCV, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, f_classif, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905054</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>0.650030</td>\n",
       "      <td>0.726911</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>0.785561</td>\n",
       "      <td>0.785303</td>\n",
       "      <td>0.416636</td>\n",
       "      <td>0.836273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>0.327691</td>\n",
       "      <td>0.770494</td>\n",
       "      <td>0.737494</td>\n",
       "      <td>0.265930</td>\n",
       "      <td>0.677964</td>\n",
       "      <td>0.180462</td>\n",
       "      <td>0.528686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890581</td>\n",
       "      <td>0.806346</td>\n",
       "      <td>0.780677</td>\n",
       "      <td>0.262780</td>\n",
       "      <td>0.330473</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>0.768104</td>\n",
       "      <td>0.638112</td>\n",
       "      <td>0.523704</td>\n",
       "      <td>0.714391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558997</td>\n",
       "      <td>0.139567</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.149787</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.545059</td>\n",
       "      <td>0.539564</td>\n",
       "      <td>0.722114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816178</td>\n",
       "      <td>0.677894</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>0.529311</td>\n",
       "      <td>0.275011</td>\n",
       "      <td>0.371895</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.469636</td>\n",
       "      <td>0.326216</td>\n",
       "      <td>0.557980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640669</td>\n",
       "      <td>0.544715</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>0.385818</td>\n",
       "      <td>-0.022494</td>\n",
       "      <td>0.495472</td>\n",
       "      <td>0.093924</td>\n",
       "      <td>0.420528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.591219</td>\n",
       "      <td>0.555190</td>\n",
       "      <td>0.546275</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.376038</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.688920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854777</td>\n",
       "      <td>0.657088</td>\n",
       "      <td>0.604125</td>\n",
       "      <td>0.766604</td>\n",
       "      <td>0.511823</td>\n",
       "      <td>0.446752</td>\n",
       "      <td>0.667355</td>\n",
       "      <td>0.634916</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.867679</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>0.742490</td>\n",
       "      <td>0.708739</td>\n",
       "      <td>0.691145</td>\n",
       "      <td>0.782443</td>\n",
       "      <td>0.781577</td>\n",
       "      <td>0.735367</td>\n",
       "      <td>0.704867</td>\n",
       "      <td>0.736210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820903</td>\n",
       "      <td>0.746328</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>0.861382</td>\n",
       "      <td>0.566985</td>\n",
       "      <td>0.129286</td>\n",
       "      <td>0.742487</td>\n",
       "      <td>0.180534</td>\n",
       "      <td>0.233673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.905054  0.830627  0.791032  0.650030  0.726911  0.794661  0.785561   \n",
       "1  0.890581  0.806346  0.780677  0.262780  0.330473  0.798218  0.768104   \n",
       "2  0.816178  0.677894  0.392524  0.529311  0.275011  0.371895  0.020806   \n",
       "3  0.879808  0.671233  0.591219  0.555190  0.546275  0.640449  0.376038   \n",
       "4  0.867679  0.811004  0.742490  0.708739  0.691145  0.782443  0.781577   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.785303  0.416636  0.836273   ...    0.819071  0.687870  0.327691   \n",
       "1  0.638112  0.523704  0.714391   ...    0.558997  0.139567  0.331483   \n",
       "2  0.469636  0.326216  0.557980   ...    0.640669  0.544715  0.014002   \n",
       "3  0.399086  0.368852  0.688920   ...    0.854777  0.657088  0.604125   \n",
       "4  0.735367  0.704867  0.736210   ...    0.820903  0.746328  0.053653   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.770494  0.737494  0.265930  0.677964  0.180462  0.528686       1  \n",
       "1  0.574336  0.149787  0.375146  0.545059  0.539564  0.722114       1  \n",
       "2  0.667235  0.385818 -0.022494  0.495472  0.093924  0.420528       1  \n",
       "3  0.766604  0.511823  0.446752  0.667355  0.634916  0.733674       1  \n",
       "4  0.861382  0.566985  0.129286  0.742487  0.180534  0.233673       1  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mri_data=pd.read_csv('Depression_control_11.12.csv',skipinitialspace=True)\n",
    "# mri_data.head()\n",
    "mri_data = pd.read_csv('SCHZ_CONTROL.csv', index_col=0)\n",
    "# mri_data = data[data.columns[:-1]]\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_data=mri_data[mri_data.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор признаков на основе модели\n",
    "# аналогично SelectFromModel, но на основе количества признаков, а не порога\n",
    "\n",
    "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
    "from sklearn.feature_selection.base import SelectorMixin\n",
    "from sklearn.feature_selection.from_model import _get_feature_importances\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "\n",
    "class SelectNFeaturesFromModel(BaseEstimator, SelectorMixin, MetaEstimatorMixin):\n",
    "    def __init__(self, estimator, n_selected, prefit=False):\n",
    "        self.estimator = estimator\n",
    "        self.n_selected = n_selected\n",
    "        self.prefit = prefit\n",
    "\n",
    "    def _get_support_mask(self):\n",
    "        if self.prefit:\n",
    "            estimator = self.estimator\n",
    "        elif hasattr(self, 'estimator_'):\n",
    "            estimator = self.estimator_\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Either fit SelectFromModel before transform or set \"prefit='\n",
    "                'True\" and pass a fitted estimator to the constructor.')\n",
    "        scores = _get_feature_importances(estimator)\n",
    "        threshold = np.sort(scores)[-self.n_selected]\n",
    "        return scores >= threshold\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if self.prefit:\n",
    "            raise NotFittedError(\n",
    "                \"Since 'prefit=True', call transform directly\")\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def scores_(self):\n",
    "        scores = _get_feature_importances(self.estimator_,)\n",
    "        return scores\n",
    "\n",
    "    @property\n",
    "    def threshold_(self):\n",
    "        scores = _get_feature_importances(self.estimator_,)\n",
    "        return np.sort(scores)[-n_selected]\n",
    "    \n",
    "    @if_delegate_has_method('estimator')\n",
    "    def partial_fit(self, X, y=None, **fit_params):\n",
    "        if self.prefit:\n",
    "            raise NotFittedError(\n",
    "                \"Since 'prefit=True', call transform directly\")\n",
    "        if not hasattr(self, \"estimator_\"):\n",
    "            self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.partial_fit(X, y, **fit_params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
    "from sklearn.feature_selection.base import SelectorMixin\n",
    "from sklearn.feature_selection.from_model import _get_feature_importances\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "\n",
    "class SelectFromGroups(BaseEstimator, SelectorMixin, MetaEstimatorMixin):\n",
    "    # groups = True-False-mask for X columns (features)\n",
    "    def __init__(self, method, groups=[]):\n",
    "        self.method = method\n",
    "        self.groups = groups\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        \n",
    "    def _get_support_mask(self):\n",
    "#         if self.prefit:\n",
    "#             estimator = self.estimator\n",
    "#         elif hasattr(self, 'estimator_'):\n",
    "#             estimator = self.estimator_\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 'Either fit SelectFromModel before transform or set \"prefit='\n",
    "#                 'True\" and pass a fitted estimator to the constructor.')\n",
    "#         scores = _get_feature_importances(estimator)\n",
    "#         threshold = np.sort(scores)[-self.n_selected]\n",
    "        return np.column_stack(supports)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        if not self.groups:\n",
    "            n_features = X.shape[1]\n",
    "            self.groups = [np.ones(n_features, dtype=bool)]\n",
    "        for group in self.groups:\n",
    "            self.method.fit(X[:, group], y)\n",
    "            self.methods.append(deepcopy(self.method))\n",
    "            self.supports.append(self.method.get_support())\n",
    "                \n",
    "    def fit_transform(self, X, y):\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        transformed = []\n",
    "        if not self.groups:\n",
    "            n_features = X.shape[1]\n",
    "            self.groups = [np.ones(n_features, dtype=bool)]\n",
    "        for group in self.groups:\n",
    "            transformed.append(self.method.fit_transform(X[:, group], y))\n",
    "            self.methods.append(deepcopy(self.method))\n",
    "            self.supports.append(self.method.get_support())\n",
    "                \n",
    "        return np.column_stack(transformed)\n",
    "    def transform(self, X):\n",
    "        transformed = []\n",
    "        if not self.methods:\n",
    "            self.method.transform(X)\n",
    "        else:\n",
    "            for group in self.groups:\n",
    "                transformed.append(self.method.transform(X[:, group]))\n",
    "        return np.column_stack(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 svc_kernel_l=None, svc_c_l=None, svc_gamma_l=None):\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', SVC(probability=True, random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if svc_kernel_l is not None:\n",
    "        param_grid['classifier__kernel'] = svc_kernel_l\n",
    "    if svc_c_l is not None:\n",
    "        param_grid['classifier__C'] = svc_c_l\n",
    "    if svc_gamma_l is not None:\n",
    "        param_grid['classifier__gamma'] = svc_gamma_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 lr_c_l=None, lr_penalty_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', LogisticRegression(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if lr_c_l is not None:\n",
    "        param_grid['classifier__C'] = lr_c_l\n",
    "    if lr_penalty_l is not None:\n",
    "        param_grid['classifier__penalty'] = lr_penalty_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rfc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 rfc_n_estimators_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', RandomForestClassifier(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if rfc_n_estimators_l is not None:\n",
    "        param_grid['classifier__n_estimators'] = rfc_n_estimators_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 knn_n_neighbors_l=None, knn_weights_l=None, knn_p_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', KNeighborsClassifier()),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if knn_n_neighbors_l is not None:\n",
    "        param_grid['classifier__n_neighbors'] = knn_n_neighbors_l\n",
    "    if knn_weights_l is not None:\n",
    "        param_grid['classifier__weights'] = knn_weights_l\n",
    "    if knn_p_l is not None:\n",
    "        param_grid['classifier__p'] = knn_p_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gbc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 gbc_n_estimators_l=None): # мб нужно варьировать больше параметров\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if gbc_n_estimators_l is not None:\n",
    "        param_grid['classifier__n_estimators'] = gbc_n_estimators_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set printoptions\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(clf_grid_dict, save_plot_to=None):\n",
    "    results = {\n",
    "            \"classifier\" : [], \n",
    "            \"best parameters\" : [],\n",
    "            \"best dim. reduction method\" : [],\n",
    "            \"mean\" : [],\n",
    "            \"std\" : []\n",
    "           }\n",
    "    \n",
    "    for clf, grid in clf_grid_dict.items():\n",
    "        results[\"classifier\"].append(clf)\n",
    "        results[\"best parameters\"].append(\", \".join(\n",
    "            [param + \" = \" + str(best_value) for param, best_value in grid.best_params_.items() if param != 'dim_reduction']))\n",
    "        results[\"best dim. reduction method\"].append(grid.best_params_['dim_reduction'])\n",
    "        idx = grid.best_index_\n",
    "        results[\"mean\"].append(grid.cv_results_['mean_test_score'][idx])\n",
    "        results[\"std\"].append(grid.cv_results_['std_test_score'][idx])\n",
    "        \n",
    "    results = pd.DataFrame(results, columns=[\"classifier\", \"best parameters\", \"best dim. reduction method\", \"mean\", \"std\"])\n",
    "    display(results.set_index(\"classifier\"))\n",
    "    \n",
    "    # draw graph\n",
    "    width = 0.9\n",
    "    for i in results.index:\n",
    "        plt.bar(i, results.loc[i, \"mean\"], width, yerr=results.loc[i, \"std\"], label=results.loc[i, \"classifier\"])\n",
    "    plt.xticks(range(results.shape[0]), results.loc[:, \"classifier\"])\n",
    "    plt.axis(ymin=0.0, ymax=1.0)\n",
    "    if save_plot_to is not None:\n",
    "        plt.savefig(save_plot_to)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best model: \")\n",
    "    clf = results.loc[results[\"mean\"].argmax(), \"classifier\"]\n",
    "    print(clf)\n",
    "    print(\"\\n\".join(\n",
    "            [param + \" = \" + str(best_value) for param, best_value in clf_grid_dict[clf].best_params_.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединенный подсчет и сравнение всех классификаторов (SVC, LR, RFC, KNN, GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grid_cv(X, y, n_splits, n_repeats, scoring, pos_label=None, random_state=None, n_jobs=1, features_groups=[], save_plot_to=None):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "    \n",
    "    n_features = [10, 20, 50, 100]\n",
    "    n_components = [10, 20]\n",
    "    \n",
    "    # list of dimensionality reduction methods\n",
    "    dim_reduction_methods = []\n",
    "    dim_reduction_methods += [SelectKBest(stats.ttest_ind, n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectKBest(f_classif, n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(RandomForestClassifier(n_estimators=100, random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(LogisticRegression(random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(ExtraTreesClassifier(n_estimators=100, random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [PCA(n, random_state=random_state) for n in n_components]\n",
    "    dim_reduction_methods += [LocallyLinearEmbedding(n_components=n, random_state=random_state) for n in n_components]\n",
    "    \n",
    "    \n",
    "    print(\"Target distribution: \")\n",
    "    print(y.value_counts(), \"\\n\")\n",
    "    if pos_label is None:\n",
    "        y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "    else:\n",
    "        y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "    \n",
    "    print(\"Training SVC...\")\n",
    "    grid_cv_svc = get_svc_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                               svc_kernel_l=[\"rbf\", \"linear\"],\n",
    "                               svc_c_l=[10 ** i for i in range(0, 4, 1)],\n",
    "                               svc_gamma_l=[10 ** i for i in range(-3, -1, 1)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_svc.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training LR...\")\n",
    "    grid_cv_lr = get_lr_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                             lr_c_l=[10 ** i for i in range(-4, -1, 1)],\n",
    "                             lr_penalty_l=[\"l1\", \"l2\"])\n",
    "    start_time = time.time()\n",
    "    grid_cv_lr.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training RFC...\")\n",
    "    grid_cv_rfc = get_rfc_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                               rfc_n_estimators_l=[i for i in range(100, 210, 30)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_rfc.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training KNN...\")\n",
    "    class_size_tr = min(y.value_counts())\n",
    "    grid_cv_knn = get_knn_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                              knn_p_l=[1, 2],\n",
    "                              knn_weights_l=[\"uniform\", \"distance\"],\n",
    "                              knn_n_neighbors_l=[i for i in range(5, class_size_tr - 1, 3)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_knn.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "\n",
    "    \n",
    "    print(\"Scoring:\", scoring)\n",
    "    print_results({\n",
    "        \"SVC\" : grid_cv_svc,\n",
    "        \"LR\" : grid_cv_lr,\n",
    "        \"RFC\" : grid_cv_rfc,\n",
    "        \"KNN\" : grid_cv_knn,\n",
    "                  }, save_plot_to=save_plot_to)\n",
    "    \n",
    "    best_model = max([grid_cv_svc, grid_cv_lr, grid_cv_rfc, grid_cv_knn], key=lambda x: x.best_score_).best_estimator_\n",
    "    \n",
    "    return best_model, grid_cv_svc, grid_cv_lr, grid_cv_rfc, grid_cv_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects = mri_data.shape[0]\n",
    "\n",
    "def repeated_cross_val_predict(estimator, X, y, cv, file=None):\n",
    "    predictions = [[] for i in range(n_objects)]\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y)):\n",
    "        estimator.fit(X.iloc[idx_tr], y.iloc[idx_tr])\n",
    "        pred_te = np.array(estimator.predict(X.iloc[idx_te]), dtype=int)\n",
    "        for i, idx in enumerate(idx_te):\n",
    "            predictions[X.index[idx]].append(idx_to_label[pred_te[i]])\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    if file is not None:\n",
    "        predictions.to_csv(file)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects = mri_data.shape[0]\n",
    "\n",
    "def repeated_cross_val_predict_proba(estimator, X, y, cv, pos_label=None, file=None):\n",
    "    \n",
    "    if pos_label is None:\n",
    "        y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "    else:\n",
    "        y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "    predictions = [[] for i in range(n_objects)]\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y_enc)):\n",
    "        estimator.fit(X.iloc[idx_tr], y_enc.iloc[idx_tr])\n",
    "        pred_te = np.array(estimator.predict_proba(X.iloc[idx_te]), dtype=float)\n",
    "        for i, idx in enumerate(idx_te):\n",
    "            predictions[X.index[idx]].append(pred_te[i, 1])\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    if file is not None:\n",
    "        predictions.to_csv(file)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file):\n",
    "    joblib.dump(model, file)\n",
    "    \n",
    "def load_model(file):\n",
    "    model = joblib.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y, probas, idx, average_repeats=False, show=True):\n",
    "    if average_repeats:\n",
    "        y_true = y\n",
    "        y_score = probas[idx].mean(axis=1)\n",
    "    else:\n",
    "        n_repeats = probas.shape[1]\n",
    "        y_true = pd.Series(np.tile(y, (n_repeats)), dtype=int)\n",
    "        y_score = probas[idx].values.T.reshape(-1, 1)\n",
    "    fpr, tpr, t = roc_curve(y_true=y_true, y_score=y_score)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel(\"False Positive rate\", fontsize=14)\n",
    "        plt.ylabel(\"True Positive rate\", fontsize=14)\n",
    "        plt.show()\n",
    "        print(\"auc =\", roc_auc_score(y_true, y_score))\n",
    "        \n",
    "    return fpr, tpr, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_fpr_threshold(fpr, t, fix_fpr=0):\n",
    "    return t[fpr <= fix_fpr][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr_fnr(fpr, tpr, fix_fpr_l=[0.1, 0.15, 0.2, 0.3]):\n",
    "    fnr_l = []\n",
    "    for fix_fpr in fix_fpr_l:\n",
    "        fnr_l.append(1 - tpr[fpr <= fix_fpr][-1])\n",
    "    fpr_fnr_table = pd.DataFrame(np.column_stack((fix_fpr_l, fnr_l)), columns=[\"False Positive rate (fixed)\", \"False Negative rate\"])\n",
    "    display(fpr_fnr_table)\n",
    "    return fpr_fnr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сейчас работает только для одномерных векторов вероятностей (одно предсказание для каждого объекта, напр. leave one out)\n",
    "def get_incorrectly_classified(y, probas, idx, fpr, t, fix_fpr_l=[0.1, 0.15, 0.2, 0.3], file=None, show=True):\n",
    "    columns = [\"False Positive rate (fixed)\", \"Threshold\", \"False Positives indexes\", \"False Negatives indexes\"]\n",
    "    t_l = []\n",
    "    false_0 = []\n",
    "    false_1 = []\n",
    "    for fix_fpr in fix_fpr_l:\n",
    "        fix_t = t[fpr <= fix_fpr][-1]\n",
    "        t_l.append(fix_t)\n",
    "        labels_t = probas > fix_t\n",
    "        labels_t = pd.Series(labels_t.values.ravel())\n",
    "        false_0.append(\", \".join(list(labels.loc[(probas[idx][np.logical_and(labels_t[idx] == 0, y == 1)]).index, \"patient_number\"])))\n",
    "        false_1.append(\", \".join(list(labels.loc[(probas[idx][np.logical_and(labels_t[idx] == 1, y == 0)]).index, \"patient_number\"])))\n",
    "              \n",
    "    t_l = np.array(t_l)\n",
    "    false_0 = np.array(false_0)\n",
    "    false_1 = np.array(false_1)\n",
    "    \n",
    "    res = pd.DataFrame(np.column_stack((fix_fpr_l, t_l)), columns=columns[:2])\n",
    "    res[\"False Positives indexes\"] = false_1\n",
    "    res[\"False Negatives indexes\"] = false_0\n",
    "    \n",
    "    if file is not None:\n",
    "        res.to_csv(file)\n",
    "        \n",
    "    if show:\n",
    "        display(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, y, model):\n",
    "    model.fit(X, y)\n",
    "#     var_th = model.named_steps['VarTh']\n",
    "#     var_th_features_idx = var_th.get_support()\n",
    "    dim_reduction = model.named_steps[\"dim_reduction\"]\n",
    "    features_idx = dim_reduction.get_support()\n",
    "#     classifier = model.named_steps[\"classifier\"]\n",
    "#     features_weights = classifier.coef_[0]\n",
    "    features = X.columns[features_idx].tolist()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sets_on_cross_val(X, y, model, cv):\n",
    "    feature_sets = []\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y)):\n",
    "        X_tr = X.loc[X.index[idx_tr]]\n",
    "        y_tr = y.loc[X.index[idx_tr]]\n",
    "        y_te = y.loc[X.index[idx_te]]\n",
    "        feature_sets.append(get_features(X_tr, y_tr, model))\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_features(features_l, classifier_l, y, p=0.5, min_common=3, file_all=None, file_frequent=None):\n",
    "    for i, features in enumerate(features_l):\n",
    "        features[\"frequency_norm\"] = features[\"frequency\"] / y.size\n",
    "        features[\"classifier\"] = classifier_l[i]\n",
    "    \n",
    "    all_features = pd.concat([features.drop(\"frequency\", axis=1) for features in features_l], axis=0)\n",
    "    all_features = all_features.reset_index().set_index(\"classifier\")\n",
    "    all_features.columns = [\"feature\", \"frequency_norm\"]\n",
    "    \n",
    "    if file_all is not None:\n",
    "        all_features.to_csv(file_all)\n",
    "        \n",
    "    frequent_features = pd.DataFrame(all_features[all_features.frequency_norm > p][\"feature\"].value_counts())\n",
    "    if file_frequent is not None:\n",
    "        frequent_features.to_csv(file_frequent)\n",
    "    \n",
    "    common_frequent_features = frequent_features[frequent_features[\"feature\"] >= min_common].index.tolist()\n",
    "    \n",
    "    return all_features, frequent_features, common_frequent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_indexes(probas_l, classifiers_l, y, idx, show=False, file=None):\n",
    "    incorr_classified_l = []\n",
    "    for i, probas in enumerate(probas_l):\n",
    "        fpr, tpr, t = plot_roc_curve(y, probas, idx, show=show)\n",
    "        incorr_classified = get_incorrectly_classified(y, probas, idx, fpr, t, show=show)\n",
    "        incorr_classified[\"classifier\"] = classifiers_l[i]\n",
    "        incorr_classified_l.append(incorr_classified)\n",
    "        \n",
    "    all_incorr_classified = pd.concat(incorr_classified_l, axis=0)\n",
    "    all_incorr_classified.set_index(\"classifier\", inplace=True)\n",
    "    \n",
    "    if file is not None:\n",
    "        all_incorr_classified.to_csv(file)\n",
    "    \n",
    "    max_fpr = all_incorr_classified[\"False Positive rate (fixed)\"].max()\n",
    "    common_false_positives = Counter(list((\", \".join(all_incorr_classified[all_incorr_classified[\"False Positive rate (fixed)\"] == max_fpr][\"False Positives indexes\"].tolist())).split(\", \")))\n",
    "    data=pd.DataFrame(common_false_positives,index=[0]).T\n",
    "    common_false_positives_ =\", \".join(data[data[0]>=3].index)    \n",
    "    \n",
    "    min_fpr = all_incorr_classified[\"False Positive rate (fixed)\"].min()\n",
    "    common_false_negatives = Counter(list((\", \".join(all_incorr_classified[all_incorr_classified[\"False Positive rate (fixed)\"] == min_fpr][\"False Negatives indexes\"].tolist())).split(\", \")))\n",
    "    data=pd.DataFrame(common_false_negatives,index=[0]).T\n",
    "    common_false_negatives_ =\", \".join(data[data[0]>=3].index)\n",
    "    \n",
    "    return all_incorr_classified, common_false_positives_, common_false_negatives_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_regions(all_features, n=0.0, importance=0.5):\n",
    "    freq_list=all_features[all_features['frequency_norm']>=n]\n",
    "    freq_list=freq_list.reset_index()\n",
    "    freq_list['feature_pure']=''\n",
    "    freq_list['feature_score']=''\n",
    "    appendix_list_thick=['_NumVert','_GrayVol','_FoldInd','_CurvInd','_GausCurv','_ThickStd','_ThickAvg','_MeanCurv','_SurfArea']\n",
    "    appendix_list_vol=['_Volume_mm3','_normMean','_normMin','_normMax','_normStdDev','_normRange','_NVoxels']\n",
    "    for i in range(len(freq_list)):\n",
    "        for j in appendix_list_thick:\n",
    "            if j in freq_list['feature'].loc[i]:\n",
    "                freq_list['feature_pure'].loc[i]=freq_list['feature'].loc[i].replace(j, '')\n",
    "                freq_list['feature_score'].loc[i]=freq_list['frequency_norm'].loc[i]/9\n",
    "        for k in appendix_list_vol:\n",
    "            if k in freq_list['feature'].loc[i]:\n",
    "                freq_list['feature_pure'].loc[i]=freq_list['feature'].loc[i].replace(k, '')\n",
    "                freq_list['feature_score'].loc[i]=freq_list['frequency_norm'].loc[i]/7\n",
    "\n",
    "    freq_pure_list=freq_list[['feature_pure','feature_score']].groupby(['feature_pure']).sum()\n",
    "    freq_pure_list=freq_pure_list.sort_values(['feature_score'], ascending=False)\n",
    "    freq_pure_list=freq_pure_list[freq_pure_list['feature_score']>=freq_pure_list['feature_score'].max()*importance]\n",
    "    print (freq_pure_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now going with test train validate\n",
    "def select_features_on_cross_val(cv, X_tr, y_tr, random_state=None):\n",
    "    # отбираем признаки    \n",
    "    # сохраняем все признаки с весами (для каждой итерации RepeatedKFold)\n",
    "    features_l = []\n",
    "    for i_tr, i_te in cv.split(X_tr, y_tr):\n",
    "        \n",
    "        selector = SelectKBest(score_func=f_classif, k=150)\n",
    "        selector.fit(X_tr.loc[X_tr.index[i_tr]], y_tr[X_tr.index[i_tr]])\n",
    "        features_idx = selector.get_support()\n",
    "        features = X_tr.columns[features_idx].tolist()\n",
    "#         selector = LogisticRegression(penalty='l1', random_state=random_state)\n",
    "#         selector.fit(X_tr.loc[X_tr.index[i_tr]], y_tr[X_tr.index[i_tr]])\n",
    "#         features_weights = selector.coef_[0]\n",
    "#         features = pd.DataFrame(sorted(list(zip(X_tr.columns, features_weights)), \n",
    "#                         key=lambda x: -abs(x[1])), columns=[\"feature\", \"weight (from classifier)\"])\n",
    "#         # оставляем только признаки с ненулевыми весами\n",
    "#         features = features.loc[features[\"weight (from classifier)\"] != 0, \"feature\"].values.tolist()\n",
    "        features_l.append(features)\n",
    "\n",
    "    # оставляем только признаки, которые вошли во все множества \n",
    "    selected_features = list(reduce(lambda x, y: set(x) & set(y), features_l))\n",
    "#     print(selected_features)\n",
    "\n",
    "    # оставляем области, которые вошли во все множества\n",
    "    regions_l = list(map(lambda x: list(map(get_feature_region, x)), features_l))\n",
    "    selected_regions = list(reduce(lambda x, y: set(x) & set(y), regions_l))\n",
    "#     print(selected_regions)\n",
    "    \n",
    "    # выбираем все признаки для этих областей\n",
    "    selected = []\n",
    "    for region in selected_regions:\n",
    "        for feature_type in types:\n",
    "            feature = region + \"_\" + feature_type\n",
    "            if feature in all_features:\n",
    "                selected.append(feature)\n",
    "    \n",
    "    return selected\n",
    "\n",
    "def cross_val_feature_selection_test(X, y, pos_label, estimator, n_splits_outer=5, n_repeats_outer=10, \n",
    "                                     n_splits=5, n_repeats=10, scoring=\"roc_auc\", random_state=None):\n",
    "    cv_outer = RepeatedStratifiedKFold(n_splits=n_splits_outer, n_repeats=n_repeats_outer, random_state=random_state)\n",
    "    cv_score_tr = []\n",
    "    score_te = []    \n",
    "    # отложим часть данных для теста\n",
    "    for idx_tr, idx_te in tqdm(cv_outer.split(X, y)):\n",
    "        X_tr = X.loc[X.index[idx_tr]]\n",
    "        X_te = X.loc[X.index[idx_te]]\n",
    "        y_tr = y.loc[X.index[idx_tr]]\n",
    "        y_te = y.loc[X.index[idx_te]]\n",
    "        \n",
    "        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "        selected = select_features_on_cross_val(cv, X_tr, y_tr, random_state)\n",
    "        print(selected)\n",
    "        \n",
    "        # качество на той части выборки, где признаки были выбраны\n",
    "        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "        scores_selected = cross_val_score(estimator, X_tr[selected], pd.Series(y_tr == pos_label, dtype=np.int), cv=cv, scoring=scoring)\n",
    "        cv_score_tr += scores_selected.tolist()\n",
    "\n",
    "        # test\n",
    "        # обучаем на всей выборке (train) \n",
    "        estimator.fit(X_tr[selected], pd.Series(y_tr == pos_label, dtype=np.int))\n",
    "        # оцениваем на отложенной части (test)\n",
    "        score_selected_test = roc_auc_score(pd.Series(y_te == pos_label, dtype=np.int), estimator.predict_proba(X_te[selected])[:, 1])\n",
    "        score_te.append(score_selected_test)\n",
    "        \n",
    "    return cv_score_tr, score_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some metrics (e.g. f1_score) can not be used for multiclass classification and require micro/macro averaging\n",
    "# scoring, scoring_multiclass = \"f1\", \"f1_micro\"\n",
    "classifiers_l = [\"svc\", \"lr\", \"rfc\", \"knn\"]\n",
    "scoring = \"roc_auc\"\n",
    "# other variants\n",
    "# scoring, scoring_multiclass = \"accuracy\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCHZ / control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "1    114\n",
      "0     44\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n",
      "(training took 5958.484095335007s)\n",
      "\n",
      "Training LR...\n",
      "(training took 186.2858214378357s)\n",
      "\n",
      "Training RFC...\n",
      "(training took 127.69375610351562s)\n",
      "\n",
      "Training KNN...\n",
      "(training took 1443.420167684555s)\n",
      "\n",
      "Scoring: roc_auc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.01</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.702292</td>\n",
       "      <td>0.095088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 190</td>\n",
       "      <td>SelectKBest(k=50, score_func=&lt;function f_classif at 0x7f4bf0a67510&gt;)</td>\n",
       "      <td>0.684208</td>\n",
       "      <td>0.086372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__gamma = 0.001, classifier__kernel = rbf, classifier__C = 10</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.711859</td>\n",
       "      <td>0.099798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 26, classifier__weights = distance, classifier__p = 2</td>\n",
       "      <td>SelectKBest(k=10, score_func=&lt;function f_classif at 0x7f4bf0a67510&gt;)</td>\n",
       "      <td>0.711553</td>\n",
       "      <td>0.079581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "LR                                           classifier__penalty = l2, classifier__C = 0.01   \n",
       "RFC                                                          classifier__n_estimators = 190   \n",
       "SVC                 classifier__gamma = 0.001, classifier__kernel = rbf, classifier__C = 10   \n",
       "KNN         classifier__n_neighbors = 26, classifier__weights = distance, classifier__p = 2   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "LR          SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "RFC                                                                                          SelectKBest(k=50, score_func=<function f_classif at 0x7f4bf0a67510>)   \n",
       "SVC         SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "KNN                                                                                          SelectKBest(k=10, score_func=<function f_classif at 0x7f4bf0a67510>)   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "LR          0.702292  0.095088  \n",
       "RFC         0.684208  0.086372  \n",
       "SVC         0.711859  0.099798  \n",
       "KNN         0.711553  0.079581  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "             n_selected=100, prefit=False)\n",
      "classifier__gamma = 0.001\n",
      "classifier__kernel = rbf\n",
      "classifier__C = 10\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_E, grid_cv_svc_mri_E, grid_cv_lr_mri_E, grid_cv_rfc_mri_E, grid_cv_knn_mri_E= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_E, \"fMRI_best_SCHZ.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158it [01:52,  1.39it/s]\n",
      "158it [01:52,  1.38it/s]\n",
      "158it [01:07,  2.36it/s]\n",
      "158it [00:22,  7.12it/s]\n",
      "158it [01:53,  1.42it/s]\n",
      "158it [01:51,  1.42it/s]\n",
      "158it [01:03,  2.41it/s]\n",
      "158it [00:23,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "## classifier_l = [\"svc\", \"lr\", \"rfc\", \"knn\"]\n",
    "grid_cv_l = [grid_cv_svc_mri_E, grid_cv_lr_mri_E, grid_cv_rfc_mri_E, grid_cv_knn_mri_E]\n",
    "best_model_l = [x.best_estimator_ for x in grid_cv_l]\n",
    "problem ='arome_SCHZ'  \n",
    "probas_l = [repeated_cross_val_predict_proba(best_model, X, y, cv=LeaveOneOut(), file=\"{}_probas_mri_{}.csv\".format(classifiers_l[i], problem)) for i, best_model in enumerate(best_model_l)]\n",
    "feature_sets_l = [get_feature_sets_on_cross_val(X, y, best_model, cv=LeaveOneOut()) for best_model in best_model_l]\n",
    "features_l = [pd.DataFrame(pd.DataFrame(data=feature_set).stack().reset_index(drop=True).value_counts(), columns=['frequency']) for feature_set in feature_sets_l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCHZ / control aroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904770</td>\n",
       "      <td>0.829369</td>\n",
       "      <td>0.792125</td>\n",
       "      <td>0.653076</td>\n",
       "      <td>0.728872</td>\n",
       "      <td>0.794980</td>\n",
       "      <td>0.787377</td>\n",
       "      <td>0.787231</td>\n",
       "      <td>0.417565</td>\n",
       "      <td>0.836704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821399</td>\n",
       "      <td>0.687904</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>0.774967</td>\n",
       "      <td>0.733535</td>\n",
       "      <td>0.268768</td>\n",
       "      <td>0.676869</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>0.531821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.806560</td>\n",
       "      <td>0.781289</td>\n",
       "      <td>0.269488</td>\n",
       "      <td>0.334397</td>\n",
       "      <td>0.799294</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.640816</td>\n",
       "      <td>0.525752</td>\n",
       "      <td>0.716471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557017</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>0.336290</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.158645</td>\n",
       "      <td>0.377989</td>\n",
       "      <td>0.548788</td>\n",
       "      <td>0.540977</td>\n",
       "      <td>0.727260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816769</td>\n",
       "      <td>0.677599</td>\n",
       "      <td>0.387493</td>\n",
       "      <td>0.527873</td>\n",
       "      <td>0.265885</td>\n",
       "      <td>0.370717</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.449543</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.559328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646365</td>\n",
       "      <td>0.545378</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.671346</td>\n",
       "      <td>0.385499</td>\n",
       "      <td>-0.010096</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>0.091793</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808305</td>\n",
       "      <td>0.571613</td>\n",
       "      <td>0.700602</td>\n",
       "      <td>0.572765</td>\n",
       "      <td>0.646205</td>\n",
       "      <td>0.686534</td>\n",
       "      <td>0.761346</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>0.588374</td>\n",
       "      <td>0.762286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639721</td>\n",
       "      <td>0.574518</td>\n",
       "      <td>0.368526</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.415526</td>\n",
       "      <td>0.851607</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.689314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879478</td>\n",
       "      <td>0.672525</td>\n",
       "      <td>0.591183</td>\n",
       "      <td>0.554872</td>\n",
       "      <td>0.548473</td>\n",
       "      <td>0.641077</td>\n",
       "      <td>0.376989</td>\n",
       "      <td>0.400039</td>\n",
       "      <td>0.367120</td>\n",
       "      <td>0.690383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855391</td>\n",
       "      <td>0.658596</td>\n",
       "      <td>0.602303</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.515096</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>0.670776</td>\n",
       "      <td>0.631877</td>\n",
       "      <td>0.731177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.904770  0.829369  0.792125  0.653076  0.728872  0.794980  0.787377   \n",
       "1  0.891253  0.806560  0.781289  0.269488  0.334397  0.799294  0.768852   \n",
       "2  0.816769  0.677599  0.387493  0.527873  0.265885  0.370717  0.020080   \n",
       "3  0.808305  0.571613  0.700602  0.572765  0.646205  0.686534  0.761346   \n",
       "4  0.879478  0.672525  0.591183  0.554872  0.548473  0.641077  0.376989   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.787231  0.417565  0.836704   ...    0.821399  0.687904  0.328590   \n",
       "1  0.640816  0.525752  0.716471   ...    0.557017  0.146031  0.336290   \n",
       "2  0.449543  0.319015  0.559328   ...    0.646365  0.545378  0.027825   \n",
       "3  0.552699  0.588374  0.762286   ...    0.639721  0.574518  0.368526   \n",
       "4  0.400039  0.367120  0.690383   ...    0.855391  0.658596  0.602303   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.774967  0.733535  0.268768  0.676869  0.178262  0.531821       0  \n",
       "1  0.576098  0.158645  0.377989  0.548788  0.540977  0.727260       0  \n",
       "2  0.671346  0.385499 -0.010096  0.493672  0.091793  0.427800       0  \n",
       "3  0.650250  0.598606  0.415526  0.851607  0.705155  0.689314       0  \n",
       "4  0.766093  0.515096  0.445765  0.670776  0.631877  0.731177       0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mri_data=pd.read_csv('Depression_control_11.12.csv',skipinitialspace=True)\n",
    "# mri_data.head()\n",
    "mri_data = pd.read_csv('aroma_SCHZ_CONTROL.csv', index_col=0)\n",
    "# mri_data = data[data.columns[:-1]]\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "0    122\n",
      "1     50\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_aS, grid_cv_svc_mri_aS, grid_cv_lr_mri_aS, grid_cv_rfc_mri_aS, grid_cv_knn_mri_aS= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.01</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.094594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 160</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>0.076772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__gamma = 0.01, classifier__kernel = rbf, classifier__C = 10</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.751172</td>\n",
       "      <td>0.087615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 32, classifier__weights = distance, classifier__p = 1</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.726841</td>\n",
       "      <td>0.115014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "LR                                           classifier__penalty = l2, classifier__C = 0.01   \n",
       "RFC                                                          classifier__n_estimators = 160   \n",
       "SVC                  classifier__gamma = 0.01, classifier__kernel = rbf, classifier__C = 10   \n",
       "KNN         classifier__n_neighbors = 32, classifier__weights = distance, classifier__p = 1   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "LR          SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "RFC         SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "SVC         SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "KNN         SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "LR          0.729848  0.094594  \n",
       "RFC         0.721195  0.076772  \n",
       "SVC         0.751172  0.087615  \n",
       "KNN         0.726841  0.115014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
      "             n_selected=100, prefit=False)\n",
      "classifier__gamma = 0.01\n",
      "classifier__kernel = rbf\n",
      "classifier__C = 10\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_aS,\n",
    "        \"LR\" : grid_cv_lr_mri_aS,\n",
    "        \"RFC\" : grid_cv_rfc_mri_aS,\n",
    "        \"KNN\" : grid_cv_knn_mri_aS,\n",
    "                  }, save_plot_to='aroma_SCHZ_CONTROL.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_aS, \"fMRI_aroma_best_SCHZ.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fmriprep SCHZ / control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_data=pd.read_csv('Depression_control_11.12.csv',skipinitialspace=True)\n",
    "# mri_data.head()\n",
    "mri_data = pd.read_csv('fmriprep_SCHZ_CONTROL.csv', index_col=0)\n",
    "# mri_data = data[data.columns[:-1]]\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    122\n",
       "1     50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_S, grid_cv_svc_mri_S, grid_cv_lr_mri_S, grid_cv_rfc_mri_S, grid_cv_knn_mri_S= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('Fill_NaN', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('StdScaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduction', SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_mri_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.01</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...</td>\n",
       "      <td>0.725591</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 130</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.718997</td>\n",
       "      <td>0.093822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__gamma = 0.001, classifier__kernel = rbf, classifier__C = 10</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...</td>\n",
       "      <td>0.732936</td>\n",
       "      <td>0.077048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 20, classifier__weights = distance, classifier__p = 1</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.704761</td>\n",
       "      <td>0.084246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "LR                                           classifier__penalty = l2, classifier__C = 0.01   \n",
       "RFC                                                          classifier__n_estimators = 130   \n",
       "SVC                 classifier__gamma = 0.001, classifier__kernel = rbf, classifier__C = 10   \n",
       "KNN         classifier__n_neighbors = 20, classifier__weights = distance, classifier__p = 1   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "LR          SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...   \n",
       "RFC         SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "SVC         SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...   \n",
       "KNN         SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "LR          0.725591  0.088000  \n",
       "RFC         0.718997  0.093822  \n",
       "SVC         0.732936  0.077048  \n",
       "KNN         0.704761  0.084246  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
      "             n_selected=100, prefit=False)\n",
      "classifier__gamma = 0.001\n",
      "classifier__kernel = rbf\n",
      "classifier__C = 10\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_S,\n",
    "        \"LR\" : grid_cv_lr_mri_S,\n",
    "        \"RFC\" : grid_cv_rfc_mri_S,\n",
    "        \"KNN\" : grid_cv_knn_mri_S,\n",
    "                  }, save_plot_to='fmriprep_SCHZ_CONTROL.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_S, \"fMRI_fmriprep_best_SCHZ.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fmriprep SCHZ/control openneuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.903161</td>\n",
       "      <td>0.840220</td>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.610086</td>\n",
       "      <td>0.692490</td>\n",
       "      <td>0.802297</td>\n",
       "      <td>0.773570</td>\n",
       "      <td>0.780192</td>\n",
       "      <td>0.368664</td>\n",
       "      <td>0.832882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787642</td>\n",
       "      <td>0.643449</td>\n",
       "      <td>0.338068</td>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.746291</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>0.096085</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909305</td>\n",
       "      <td>0.802791</td>\n",
       "      <td>0.838261</td>\n",
       "      <td>0.043383</td>\n",
       "      <td>0.082807</td>\n",
       "      <td>0.803068</td>\n",
       "      <td>0.809212</td>\n",
       "      <td>0.416151</td>\n",
       "      <td>0.442813</td>\n",
       "      <td>0.780733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.206885</td>\n",
       "      <td>0.176679</td>\n",
       "      <td>0.610826</td>\n",
       "      <td>0.264911</td>\n",
       "      <td>0.138920</td>\n",
       "      <td>0.441210</td>\n",
       "      <td>0.425356</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814521</td>\n",
       "      <td>0.659220</td>\n",
       "      <td>0.405604</td>\n",
       "      <td>0.478532</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>0.053502</td>\n",
       "      <td>0.349824</td>\n",
       "      <td>0.160864</td>\n",
       "      <td>0.540026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536216</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.633059</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.197323</td>\n",
       "      <td>0.480678</td>\n",
       "      <td>0.323474</td>\n",
       "      <td>0.352620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803096</td>\n",
       "      <td>0.623738</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.553537</td>\n",
       "      <td>0.644795</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.774026</td>\n",
       "      <td>0.548577</td>\n",
       "      <td>0.559302</td>\n",
       "      <td>0.758565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607646</td>\n",
       "      <td>0.598106</td>\n",
       "      <td>0.116864</td>\n",
       "      <td>0.620691</td>\n",
       "      <td>0.652045</td>\n",
       "      <td>0.273250</td>\n",
       "      <td>0.801309</td>\n",
       "      <td>0.595647</td>\n",
       "      <td>0.552837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.611540</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>0.521051</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.347330</td>\n",
       "      <td>0.372602</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848746</td>\n",
       "      <td>0.639268</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.689398</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>0.375309</td>\n",
       "      <td>0.683850</td>\n",
       "      <td>0.640729</td>\n",
       "      <td>0.704982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.903161  0.840220  0.799509  0.610086  0.692490  0.802297  0.773570   \n",
       "1  0.909305  0.802791  0.838261  0.043383  0.082807  0.803068  0.809212   \n",
       "2  0.814521  0.659220  0.405604  0.478532  0.200010  0.442241  0.053502   \n",
       "3  0.803096  0.623738  0.697469  0.553537  0.644795  0.679426  0.774026   \n",
       "4  0.875554  0.666578  0.611540  0.528136  0.521051  0.648060  0.388698   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.780192  0.368664  0.832882   ...    0.787642  0.643449  0.338068   \n",
       "1  0.416151  0.442813  0.780733   ...    0.616644  0.206885  0.176679   \n",
       "2  0.349824  0.160864  0.540026   ...    0.536216  0.468293  0.037932   \n",
       "3  0.548577  0.559302  0.758565   ...    0.607646  0.598106  0.116864   \n",
       "4  0.347330  0.372602  0.683579   ...    0.848746  0.639268  0.588427   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.675770  0.746291  0.280110  0.617764  0.096085  0.509282       0  \n",
       "1  0.610826  0.264911  0.138920  0.441210  0.425356  0.471542       0  \n",
       "2  0.633059  0.294800  0.197323  0.480678  0.323474  0.352620       0  \n",
       "3  0.620691  0.652045  0.273250  0.801309  0.595647  0.552837       0  \n",
       "4  0.689398  0.392779  0.375309  0.683850  0.640729  0.704982       0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data = pd.read_csv('openneuro_SCHZ_CONTROL.csv', index_col=0)\n",
    "# mri_data = data[data.columns[:-1]]\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "0    122\n",
      "1     50\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_oS, grid_cv_svc_mri_oS, grid_cv_lr_mri_oS, grid_cv_rfc_mri_oS, grid_cv_knn_mri_oS= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_oS, \"fMRI_openneuro_best_SCHZ.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.001</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.700426</td>\n",
       "      <td>0.109431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 190</td>\n",
       "      <td>SelectKBest(k=100, score_func=&lt;function f_classif at 0x7f4bf0a67510&gt;)</td>\n",
       "      <td>0.683771</td>\n",
       "      <td>0.096490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__gamma = 0.001, classifier__kernel = linear, classifier__C = 100</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.091180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 44, classifier__weights = distance, classifier__p = 1</td>\n",
       "      <td>SelectKBest(k=50, score_func=&lt;function f_classif at 0x7f4bf0a67510&gt;)</td>\n",
       "      <td>0.693349</td>\n",
       "      <td>0.093311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "LR                                          classifier__penalty = l2, classifier__C = 0.001   \n",
       "RFC                                                          classifier__n_estimators = 190   \n",
       "SVC             classifier__gamma = 0.001, classifier__kernel = linear, classifier__C = 100   \n",
       "KNN         classifier__n_neighbors = 44, classifier__weights = distance, classifier__p = 1   \n",
       "\n",
       "                                                                                                      best dim. reduction method  \\\n",
       "classifier                                                                                                                         \n",
       "LR          PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "RFC                                                        SelectKBest(k=100, score_func=<function f_classif at 0x7f4bf0a67510>)   \n",
       "SVC         PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "KNN                                                         SelectKBest(k=50, score_func=<function f_classif at 0x7f4bf0a67510>)   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "LR          0.700426  0.109431  \n",
       "RFC         0.683771  0.096490  \n",
       "SVC         0.711111  0.091180  \n",
       "KNN         0.693349  0.093311  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "classifier__gamma = 0.001\n",
      "classifier__kernel = linear\n",
      "classifier__C = 100\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_oS,\n",
    "        \"LR\" : grid_cv_lr_mri_oS,\n",
    "        \"RFC\" : grid_cv_rfc_mri_oS,\n",
    "        \"KNN\" : grid_cv_knn_mri_oS,\n",
    "                  }, save_plot_to='openneuro_SCHZ_CONTROL.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
