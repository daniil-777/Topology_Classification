{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "%pylab inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, StratifiedShuffleSplit, cross_val_score, cross_val_predict, GridSearchCV, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, f_classif, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор признаков на основе модели\n",
    "# аналогично SelectFromModel, но на основе количества признаков, а не порога\n",
    "\n",
    "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
    "from sklearn.feature_selection.base import SelectorMixin\n",
    "from sklearn.feature_selection.from_model import _get_feature_importances\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "\n",
    "class SelectNFeaturesFromModel(BaseEstimator, SelectorMixin, MetaEstimatorMixin):\n",
    "    def __init__(self, estimator, n_selected, prefit=False):\n",
    "        self.estimator = estimator\n",
    "        self.n_selected = n_selected\n",
    "        self.prefit = prefit\n",
    "\n",
    "    def _get_support_mask(self):\n",
    "        if self.prefit:\n",
    "            estimator = self.estimator\n",
    "        elif hasattr(self, 'estimator_'):\n",
    "            estimator = self.estimator_\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Either fit SelectFromModel before transform or set \"prefit='\n",
    "                'True\" and pass a fitted estimator to the constructor.')\n",
    "        scores = _get_feature_importances(estimator)\n",
    "        threshold = np.sort(scores)[-self.n_selected]\n",
    "        return scores >= threshold\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if self.prefit:\n",
    "            raise NotFittedError(\n",
    "                \"Since 'prefit=True', call transform directly\")\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def scores_(self):\n",
    "        scores = _get_feature_importances(self.estimator_,)\n",
    "        return scores\n",
    "\n",
    "    @property\n",
    "    def threshold_(self):\n",
    "        scores = _get_feature_importances(self.estimator_,)\n",
    "        return np.sort(scores)[-n_selected]\n",
    "    \n",
    "    @if_delegate_has_method('estimator')\n",
    "    def partial_fit(self, X, y=None, **fit_params):\n",
    "        if self.prefit:\n",
    "            raise NotFittedError(\n",
    "                \"Since 'prefit=True', call transform directly\")\n",
    "        if not hasattr(self, \"estimator_\"):\n",
    "            self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.partial_fit(X, y, **fit_params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
    "from sklearn.feature_selection.base import SelectorMixin\n",
    "from sklearn.feature_selection.from_model import _get_feature_importances\n",
    "from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "\n",
    "class SelectFromGroups(BaseEstimator, SelectorMixin, MetaEstimatorMixin):\n",
    "    # groups = True-False-mask for X columns (features)\n",
    "    def __init__(self, method, groups=[]):\n",
    "        self.method = method\n",
    "        self.groups = groups\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        \n",
    "    def _get_support_mask(self):\n",
    "#         if self.prefit:\n",
    "#             estimator = self.estimator\n",
    "#         elif hasattr(self, 'estimator_'):\n",
    "#             estimator = self.estimator_\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 'Either fit SelectFromModel before transform or set \"prefit='\n",
    "#                 'True\" and pass a fitted estimator to the constructor.')\n",
    "#         scores = _get_feature_importances(estimator)\n",
    "#         threshold = np.sort(scores)[-self.n_selected]\n",
    "        return np.column_stack(supports)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        if not self.groups:\n",
    "            n_features = X.shape[1]\n",
    "            self.groups = [np.ones(n_features, dtype=bool)]\n",
    "        for group in self.groups:\n",
    "            self.method.fit(X[:, group], y)\n",
    "            self.methods.append(deepcopy(self.method))\n",
    "            self.supports.append(self.method.get_support())\n",
    "                \n",
    "    def fit_transform(self, X, y):\n",
    "        self.methods = []\n",
    "        self.supports = []\n",
    "        transformed = []\n",
    "        if not self.groups:\n",
    "            n_features = X.shape[1]\n",
    "            self.groups = [np.ones(n_features, dtype=bool)]\n",
    "        for group in self.groups:\n",
    "            transformed.append(self.method.fit_transform(X[:, group], y))\n",
    "            self.methods.append(deepcopy(self.method))\n",
    "            self.supports.append(self.method.get_support())\n",
    "                \n",
    "        return np.column_stack(transformed)\n",
    "    def transform(self, X):\n",
    "        transformed = []\n",
    "        if not self.methods:\n",
    "            self.method.transform(X)\n",
    "        else:\n",
    "            for group in self.groups:\n",
    "                transformed.append(self.method.transform(X[:, group]))\n",
    "        return np.column_stack(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 svc_kernel_l=None, svc_c_l=None, svc_gamma_l=None):\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', SVC(probability=True, random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if svc_kernel_l is not None:\n",
    "        param_grid['classifier__kernel'] = svc_kernel_l\n",
    "    if svc_c_l is not None:\n",
    "        param_grid['classifier__C'] = svc_c_l\n",
    "    if svc_gamma_l is not None:\n",
    "        param_grid['classifier__gamma'] = svc_gamma_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 lr_c_l=None, lr_penalty_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', LogisticRegression(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if lr_c_l is not None:\n",
    "        param_grid['classifier__C'] = lr_c_l\n",
    "    if lr_penalty_l is not None:\n",
    "        param_grid['classifier__penalty'] = lr_penalty_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rfc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 rfc_n_estimators_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', RandomForestClassifier(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if rfc_n_estimators_l is not None:\n",
    "        param_grid['classifier__n_estimators'] = rfc_n_estimators_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 knn_n_neighbors_l=None, knn_weights_l=None, knn_p_l=None):\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', KNeighborsClassifier()),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if knn_n_neighbors_l is not None:\n",
    "        param_grid['classifier__n_neighbors'] = knn_n_neighbors_l\n",
    "    if knn_weights_l is not None:\n",
    "        param_grid['classifier__weights'] = knn_weights_l\n",
    "    if knn_p_l is not None:\n",
    "        param_grid['classifier__p'] = knn_p_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gbc_grid(cv, dim_reduction_methods, scoring, random_state=None, n_jobs=1,\n",
    "                 gbc_n_estimators_l=None): # мб нужно варьировать больше параметров\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"Fill_NaN\", Imputer(strategy=\"median\")),\n",
    "        ('StdScaler', StandardScaler()),\n",
    "#         (\"VarTh\", VarianceThreshold()),\n",
    "        ('dim_reduction', SelectKBest(stats.ttest_ind)),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'dim_reduction': dim_reduction_methods,\n",
    "    }\n",
    "    if gbc_n_estimators_l is not None:\n",
    "        param_grid['classifier__n_estimators'] = gbc_n_estimators_l\n",
    "    \n",
    "    return GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set printoptions\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(clf_grid_dict, save_plot_to=None):\n",
    "    results = {\n",
    "            \"classifier\" : [], \n",
    "            \"best parameters\" : [],\n",
    "            \"best dim. reduction method\" : [],\n",
    "            \"mean\" : [],\n",
    "            \"std\" : []\n",
    "           }\n",
    "    \n",
    "    for clf, grid in clf_grid_dict.items():\n",
    "        results[\"classifier\"].append(clf)\n",
    "        results[\"best parameters\"].append(\", \".join(\n",
    "            [param + \" = \" + str(best_value) for param, best_value in grid.best_params_.items() if param != 'dim_reduction']))\n",
    "        results[\"best dim. reduction method\"].append(grid.best_params_['dim_reduction'])\n",
    "        idx = grid.best_index_\n",
    "        results[\"mean\"].append(grid.cv_results_['mean_test_score'][idx])\n",
    "        results[\"std\"].append(grid.cv_results_['std_test_score'][idx])\n",
    "        \n",
    "    results = pd.DataFrame(results, columns=[\"classifier\", \"best parameters\", \"best dim. reduction method\", \"mean\", \"std\"])\n",
    "    display(results.set_index(\"classifier\"))\n",
    "    \n",
    "    # draw graph\n",
    "    width = 0.9\n",
    "    for i in results.index:\n",
    "        plt.bar(i, results.loc[i, \"mean\"], width, yerr=results.loc[i, \"std\"], label=results.loc[i, \"classifier\"])\n",
    "    plt.xticks(range(results.shape[0]), results.loc[:, \"classifier\"])\n",
    "    plt.axis(ymin=0.0, ymax=1.0)\n",
    "    if save_plot_to is not None:\n",
    "        plt.savefig(save_plot_to)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best model: \")\n",
    "    clf = results.loc[results[\"mean\"].argmax(), \"classifier\"]\n",
    "    print(clf)\n",
    "    print(\"\\n\".join(\n",
    "            [param + \" = \" + str(best_value) for param, best_value in clf_grid_dict[clf].best_params_.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединенный подсчет и сравнение всех классификаторов (SVC, LR, RFC, KNN, GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grid_cv(X, y, n_splits, n_repeats, scoring, pos_label=None, random_state=None, n_jobs=1, features_groups=[], save_plot_to=None):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "    \n",
    "    n_features = [10, 20, 50, 100]\n",
    "    n_components = [10, 20]\n",
    "    \n",
    "    # list of dimensionality reduction methods\n",
    "    dim_reduction_methods = []\n",
    "    dim_reduction_methods += [SelectKBest(stats.ttest_ind, n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectKBest(f_classif, n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(RandomForestClassifier(n_estimators=100, random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(LogisticRegression(random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [SelectNFeaturesFromModel(ExtraTreesClassifier(n_estimators=100, random_state=random_state), n) for n in n_features]\n",
    "    dim_reduction_methods += [PCA(n, random_state=random_state) for n in n_components]\n",
    "    dim_reduction_methods += [LocallyLinearEmbedding(n_components=n, random_state=random_state) for n in n_components]\n",
    "    \n",
    "    \n",
    "    print(\"Target distribution: \")\n",
    "    print(y.value_counts(), \"\\n\")\n",
    "    if pos_label is None:\n",
    "        y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "    else:\n",
    "        y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "    \n",
    "    print(\"Training SVC...\")\n",
    "    grid_cv_svc = get_svc_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                               svc_kernel_l=[\"rbf\", \"linear\"],\n",
    "                               svc_c_l=[10 ** i for i in range(0, 4, 1)],\n",
    "                               svc_gamma_l=[10 ** i for i in range(-3, -1, 1)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_svc.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training LR...\")\n",
    "    grid_cv_lr = get_lr_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                             lr_c_l=[10 ** i for i in range(-4, -1, 1)],\n",
    "                             lr_penalty_l=[\"l1\", \"l2\"])\n",
    "    start_time = time.time()\n",
    "    grid_cv_lr.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training RFC...\")\n",
    "    grid_cv_rfc = get_rfc_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                               rfc_n_estimators_l=[i for i in range(100, 210, 30)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_rfc.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    print(\"Training KNN...\")\n",
    "    class_size_tr = min(y.value_counts())\n",
    "    grid_cv_knn = get_knn_grid(cv, dim_reduction_methods, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                              knn_p_l=[1, 2],\n",
    "                              knn_weights_l=[\"uniform\", \"distance\"],\n",
    "                              knn_n_neighbors_l=[i for i in range(5, class_size_tr - 1, 3)])\n",
    "    start_time = time.time()\n",
    "    grid_cv_knn.fit(X, y_enc)\n",
    "    print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "\n",
    "    \n",
    "    print(\"Scoring:\", scoring)\n",
    "    print_results({\n",
    "        \"SVC\" : grid_cv_svc,\n",
    "        \"LR\" : grid_cv_lr,\n",
    "        \"RFC\" : grid_cv_rfc,\n",
    "        \"KNN\" : grid_cv_knn,\n",
    "                  }, save_plot_to=save_plot_to)\n",
    "    \n",
    "    best_model = max([grid_cv_svc, grid_cv_lr, grid_cv_rfc, grid_cv_knn], key=lambda x: x.best_score_).best_estimator_\n",
    "    \n",
    "    return best_model, grid_cv_svc, grid_cv_lr, grid_cv_rfc, grid_cv_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_cross_val_predict(estimator, X, y, cv, file=None):\n",
    "    predictions = [[] for i in range(n_objects)]\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y)):\n",
    "        estimator.fit(X.iloc[idx_tr], y.iloc[idx_tr])\n",
    "        pred_te = np.array(estimator.predict(X.iloc[idx_te]), dtype=int)\n",
    "        for i, idx in enumerate(idx_te):\n",
    "            predictions[X.index[idx]].append(idx_to_label[pred_te[i]])\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    if file is not None:\n",
    "        predictions.to_csv(file)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_cross_val_predict_proba(estimator, X, y, cv, pos_label=None, file=None):\n",
    "    \n",
    "    if pos_label is None:\n",
    "        y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "    else:\n",
    "        y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "    predictions = [[] for i in range(n_objects)]\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y_enc)):\n",
    "        estimator.fit(X.iloc[idx_tr], y_enc.iloc[idx_tr])\n",
    "        pred_te = np.array(estimator.predict_proba(X.iloc[idx_te]), dtype=float)\n",
    "        for i, idx in enumerate(idx_te):\n",
    "            predictions[X.index[idx]].append(pred_te[i, 1])\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    if file is not None:\n",
    "        predictions.to_csv(file)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file):\n",
    "    joblib.dump(model, file)\n",
    "    \n",
    "def load_model(file):\n",
    "    model = joblib.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y, probas, idx, average_repeats=False, show=True):\n",
    "    if average_repeats:\n",
    "        y_true = y\n",
    "        y_score = probas[idx].mean(axis=1)\n",
    "    else:\n",
    "        n_repeats = probas.shape[1]\n",
    "        y_true = pd.Series(np.tile(y, (n_repeats)), dtype=int)\n",
    "        y_score = probas[idx].values.T.reshape(-1, 1)\n",
    "    fpr, tpr, t = roc_curve(y_true=y_true, y_score=y_score)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel(\"False Positive rate\", fontsize=14)\n",
    "        plt.ylabel(\"True Positive rate\", fontsize=14)\n",
    "        plt.show()\n",
    "        print(\"auc =\", roc_auc_score(y_true, y_score))\n",
    "        \n",
    "    return fpr, tpr, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_fpr_threshold(fpr, t, fix_fpr=0):\n",
    "    return t[fpr <= fix_fpr][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr_fnr(fpr, tpr, fix_fpr_l=[0.1, 0.15, 0.2, 0.3]):\n",
    "    fnr_l = []\n",
    "    for fix_fpr in fix_fpr_l:\n",
    "        fnr_l.append(1 - tpr[fpr <= fix_fpr][-1])\n",
    "    fpr_fnr_table = pd.DataFrame(np.column_stack((fix_fpr_l, fnr_l)), columns=[\"False Positive rate (fixed)\", \"False Negative rate\"])\n",
    "    display(fpr_fnr_table)\n",
    "    return fpr_fnr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сейчас работает только для одномерных векторов вероятностей (одно предсказание для каждого объекта, напр. leave one out)\n",
    "def get_incorrectly_classified(y, probas, idx, fpr, t, fix_fpr_l=[0.1, 0.15, 0.2, 0.3], file=None, show=True):\n",
    "    columns = [\"False Positive rate (fixed)\", \"Threshold\", \"False Positives indexes\", \"False Negatives indexes\"]\n",
    "    t_l = []\n",
    "    false_0 = []\n",
    "    false_1 = []\n",
    "    for fix_fpr in fix_fpr_l:\n",
    "        fix_t = t[fpr <= fix_fpr][-1]\n",
    "        t_l.append(fix_t)\n",
    "        labels_t = probas > fix_t\n",
    "        labels_t = pd.Series(labels_t.values.ravel())\n",
    "        false_0.append(\", \".join(list(labels.loc[(probas[idx][np.logical_and(labels_t[idx] == 0, y == 1)]).index, \"patient_number\"])))\n",
    "        false_1.append(\", \".join(list(labels.loc[(probas[idx][np.logical_and(labels_t[idx] == 1, y == 0)]).index, \"patient_number\"])))\n",
    "              \n",
    "    t_l = np.array(t_l)\n",
    "    false_0 = np.array(false_0)\n",
    "    false_1 = np.array(false_1)\n",
    "    \n",
    "    res = pd.DataFrame(np.column_stack((fix_fpr_l, t_l)), columns=columns[:2])\n",
    "    res[\"False Positives indexes\"] = false_1\n",
    "    res[\"False Negatives indexes\"] = false_0\n",
    "    \n",
    "    if file is not None:\n",
    "        res.to_csv(file)\n",
    "        \n",
    "    if show:\n",
    "        display(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X, y, model):\n",
    "    model.fit(X, y)\n",
    "#     var_th = model.named_steps['VarTh']\n",
    "#     var_th_features_idx = var_th.get_support()\n",
    "    dim_reduction = model.named_steps[\"dim_reduction\"]\n",
    "    features_idx = dim_reduction.get_support()\n",
    "#     classifier = model.named_steps[\"classifier\"]\n",
    "#     features_weights = classifier.coef_[0]\n",
    "    features = X.columns[features_idx].tolist()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sets_on_cross_val(X, y, model, cv):\n",
    "    feature_sets = []\n",
    "    for idx_tr, idx_te in tqdm(cv.split(X, y)):\n",
    "        X_tr = X.loc[X.index[idx_tr]]\n",
    "        y_tr = y.loc[X.index[idx_tr]]\n",
    "        y_te = y.loc[X.index[idx_te]]\n",
    "        feature_sets.append(get_features(X_tr, y_tr, model))\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_features(features_l, classifier_l, y, p=0.5, min_common=3, file_all=None, file_frequent=None):\n",
    "    for i, features in enumerate(features_l):\n",
    "        features[\"frequency_norm\"] = features[\"frequency\"] / y.size\n",
    "        features[\"classifier\"] = classifier_l[i]\n",
    "    \n",
    "    all_features = pd.concat([features.drop(\"frequency\", axis=1) for features in features_l], axis=0)\n",
    "    all_features = all_features.reset_index().set_index(\"classifier\")\n",
    "    all_features.columns = [\"feature\", \"frequency_norm\"]\n",
    "    \n",
    "    if file_all is not None:\n",
    "        all_features.to_csv(file_all)\n",
    "        \n",
    "    frequent_features = pd.DataFrame(all_features[all_features.frequency_norm > p][\"feature\"].value_counts())\n",
    "    if file_frequent is not None:\n",
    "        frequent_features.to_csv(file_frequent)\n",
    "    \n",
    "    common_frequent_features = frequent_features[frequent_features[\"feature\"] >= min_common].index.tolist()\n",
    "    \n",
    "    return all_features, frequent_features, common_frequent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_indexes(probas_l, classifiers_l, y, idx, show=False, file=None):\n",
    "    incorr_classified_l = []\n",
    "    for i, probas in enumerate(probas_l):\n",
    "        fpr, tpr, t = plot_roc_curve(y, probas, idx, show=show)\n",
    "        incorr_classified = get_incorrectly_classified(y, probas, idx, fpr, t, show=show)\n",
    "        incorr_classified[\"classifier\"] = classifiers_l[i]\n",
    "        incorr_classified_l.append(incorr_classified)\n",
    "        \n",
    "    all_incorr_classified = pd.concat(incorr_classified_l, axis=0)\n",
    "    all_incorr_classified.set_index(\"classifier\", inplace=True)\n",
    "    \n",
    "    if file is not None:\n",
    "        all_incorr_classified.to_csv(file)\n",
    "    \n",
    "    max_fpr = all_incorr_classified[\"False Positive rate (fixed)\"].max()\n",
    "    common_false_positives = Counter(list((\", \".join(all_incorr_classified[all_incorr_classified[\"False Positive rate (fixed)\"] == max_fpr][\"False Positives indexes\"].tolist())).split(\", \")))\n",
    "    data=pd.DataFrame(common_false_positives,index=[0]).T\n",
    "    common_false_positives_ =\", \".join(data[data[0]>=3].index)    \n",
    "    \n",
    "    min_fpr = all_incorr_classified[\"False Positive rate (fixed)\"].min()\n",
    "    common_false_negatives = Counter(list((\", \".join(all_incorr_classified[all_incorr_classified[\"False Positive rate (fixed)\"] == min_fpr][\"False Negatives indexes\"].tolist())).split(\", \")))\n",
    "    data=pd.DataFrame(common_false_negatives,index=[0]).T\n",
    "    common_false_negatives_ =\", \".join(data[data[0]>=3].index)\n",
    "    \n",
    "    return all_incorr_classified, common_false_positives_, common_false_negatives_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_regions(all_features, n=0.0, importance=0.5):\n",
    "    freq_list=all_features[all_features['frequency_norm']>=n]\n",
    "    freq_list=freq_list.reset_index()\n",
    "    freq_list['feature_pure']=''\n",
    "    freq_list['feature_score']=''\n",
    "    appendix_list_thick=['_NumVert','_GrayVol','_FoldInd','_CurvInd','_GausCurv','_ThickStd','_ThickAvg','_MeanCurv','_SurfArea']\n",
    "    appendix_list_vol=['_Volume_mm3','_normMean','_normMin','_normMax','_normStdDev','_normRange','_NVoxels']\n",
    "    for i in range(len(freq_list)):\n",
    "        for j in appendix_list_thick:\n",
    "            if j in freq_list['feature'].loc[i]:\n",
    "                freq_list['feature_pure'].loc[i]=freq_list['feature'].loc[i].replace(j, '')\n",
    "                freq_list['feature_score'].loc[i]=freq_list['frequency_norm'].loc[i]/9\n",
    "        for k in appendix_list_vol:\n",
    "            if k in freq_list['feature'].loc[i]:\n",
    "                freq_list['feature_pure'].loc[i]=freq_list['feature'].loc[i].replace(k, '')\n",
    "                freq_list['feature_score'].loc[i]=freq_list['frequency_norm'].loc[i]/7\n",
    "\n",
    "    freq_pure_list=freq_list[['feature_pure','feature_score']].groupby(['feature_pure']).sum()\n",
    "    freq_pure_list=freq_pure_list.sort_values(['feature_score'], ascending=False)\n",
    "    freq_pure_list=freq_pure_list[freq_pure_list['feature_score']>=freq_pure_list['feature_score'].max()*importance]\n",
    "    print (freq_pure_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now going with test train validate\n",
    "def select_features_on_cross_val(cv, X_tr, y_tr, random_state=None):\n",
    "    # отбираем признаки    \n",
    "    # сохраняем все признаки с весами (для каждой итерации RepeatedKFold)\n",
    "    features_l = []\n",
    "    for i_tr, i_te in cv.split(X_tr, y_tr):\n",
    "        \n",
    "        selector = SelectKBest(score_func=f_classif, k=150)\n",
    "        selector.fit(X_tr.loc[X_tr.index[i_tr]], y_tr[X_tr.index[i_tr]])\n",
    "        features_idx = selector.get_support()\n",
    "        features = X_tr.columns[features_idx].tolist()\n",
    "#         selector = LogisticRegression(penalty='l1', random_state=random_state)\n",
    "#         selector.fit(X_tr.loc[X_tr.index[i_tr]], y_tr[X_tr.index[i_tr]])\n",
    "#         features_weights = selector.coef_[0]\n",
    "#         features = pd.DataFrame(sorted(list(zip(X_tr.columns, features_weights)), \n",
    "#                         key=lambda x: -abs(x[1])), columns=[\"feature\", \"weight (from classifier)\"])\n",
    "#         # оставляем только признаки с ненулевыми весами\n",
    "#         features = features.loc[features[\"weight (from classifier)\"] != 0, \"feature\"].values.tolist()\n",
    "        features_l.append(features)\n",
    "\n",
    "    # оставляем только признаки, которые вошли во все множества \n",
    "    selected_features = list(reduce(lambda x, y: set(x) & set(y), features_l))\n",
    "#     print(selected_features)\n",
    "\n",
    "    # оставляем области, которые вошли во все множества\n",
    "    regions_l = list(map(lambda x: list(map(get_feature_region, x)), features_l))\n",
    "    selected_regions = list(reduce(lambda x, y: set(x) & set(y), regions_l))\n",
    "#     print(selected_regions)\n",
    "    \n",
    "    # выбираем все признаки для этих областей\n",
    "    selected = []\n",
    "    for region in selected_regions:\n",
    "        for feature_type in types:\n",
    "            feature = region + \"_\" + feature_type\n",
    "            if feature in all_features:\n",
    "                selected.append(feature)\n",
    "    \n",
    "    return selected\n",
    "\n",
    "def cross_val_feature_selection_test(X, y, pos_label, estimator, n_splits_outer=5, n_repeats_outer=10, \n",
    "                                     n_splits=5, n_repeats=10, scoring=\"roc_auc\", random_state=None):\n",
    "    cv_outer = RepeatedStratifiedKFold(n_splits=n_splits_outer, n_repeats=n_repeats_outer, random_state=random_state)\n",
    "    cv_score_tr = []\n",
    "    score_te = []    \n",
    "    # отложим часть данных для теста\n",
    "    for idx_tr, idx_te in tqdm(cv_outer.split(X, y)):\n",
    "        X_tr = X.loc[X.index[idx_tr]]\n",
    "        X_te = X.loc[X.index[idx_te]]\n",
    "        y_tr = y.loc[X.index[idx_tr]]\n",
    "        y_te = y.loc[X.index[idx_te]]\n",
    "        \n",
    "        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "        selected = select_features_on_cross_val(cv, X_tr, y_tr, random_state)\n",
    "        print(selected)\n",
    "        \n",
    "        # качество на той части выборки, где признаки были выбраны\n",
    "        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "        scores_selected = cross_val_score(estimator, X_tr[selected], pd.Series(y_tr == pos_label, dtype=np.int), cv=cv, scoring=scoring)\n",
    "        cv_score_tr += scores_selected.tolist()\n",
    "\n",
    "        # test\n",
    "        # обучаем на всей выборке (train) \n",
    "        estimator.fit(X_tr[selected], pd.Series(y_tr == pos_label, dtype=np.int))\n",
    "        # оцениваем на отложенной части (test)\n",
    "        score_selected_test = roc_auc_score(pd.Series(y_te == pos_label, dtype=np.int), estimator.predict_proba(X_te[selected])[:, 1])\n",
    "        score_te.append(score_selected_test)\n",
    "        \n",
    "    return cv_score_tr, score_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some metrics (e.g. f1_score) can not be used for multiclass classification and require micro/macro averaging\n",
    "# scoring, scoring_multiclass = \"f1\", \"f1_micro\"\n",
    "classifiers_l = [\"svc\", \"lr\", \"rfc\", \"knn\"]\n",
    "scoring = \"roc_auc\"\n",
    "# other variants\n",
    "# scoring, scoring_multiclass = \"accuracy\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIPOLAR / control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905054</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>0.650030</td>\n",
       "      <td>0.726911</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>0.785561</td>\n",
       "      <td>0.785303</td>\n",
       "      <td>0.416636</td>\n",
       "      <td>0.836273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>0.327691</td>\n",
       "      <td>0.770494</td>\n",
       "      <td>0.737494</td>\n",
       "      <td>0.265930</td>\n",
       "      <td>0.677964</td>\n",
       "      <td>0.180462</td>\n",
       "      <td>0.528686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890581</td>\n",
       "      <td>0.806346</td>\n",
       "      <td>0.780677</td>\n",
       "      <td>0.262780</td>\n",
       "      <td>0.330473</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>0.768104</td>\n",
       "      <td>0.638112</td>\n",
       "      <td>0.523704</td>\n",
       "      <td>0.714391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558997</td>\n",
       "      <td>0.139567</td>\n",
       "      <td>0.331483</td>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.149787</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.545059</td>\n",
       "      <td>0.539564</td>\n",
       "      <td>0.722114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816178</td>\n",
       "      <td>0.677894</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>0.529311</td>\n",
       "      <td>0.275011</td>\n",
       "      <td>0.371895</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.469636</td>\n",
       "      <td>0.326216</td>\n",
       "      <td>0.557980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640669</td>\n",
       "      <td>0.544715</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>0.385818</td>\n",
       "      <td>-0.022494</td>\n",
       "      <td>0.495472</td>\n",
       "      <td>0.093924</td>\n",
       "      <td>0.420528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.807725</td>\n",
       "      <td>0.576972</td>\n",
       "      <td>0.699284</td>\n",
       "      <td>0.571747</td>\n",
       "      <td>0.646620</td>\n",
       "      <td>0.685664</td>\n",
       "      <td>0.762300</td>\n",
       "      <td>0.548918</td>\n",
       "      <td>0.586436</td>\n",
       "      <td>0.762267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637614</td>\n",
       "      <td>0.574696</td>\n",
       "      <td>0.365580</td>\n",
       "      <td>0.647420</td>\n",
       "      <td>0.596575</td>\n",
       "      <td>0.410199</td>\n",
       "      <td>0.851912</td>\n",
       "      <td>0.704787</td>\n",
       "      <td>0.691468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.591219</td>\n",
       "      <td>0.555190</td>\n",
       "      <td>0.546275</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.376038</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.688920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854777</td>\n",
       "      <td>0.657088</td>\n",
       "      <td>0.604125</td>\n",
       "      <td>0.766604</td>\n",
       "      <td>0.511823</td>\n",
       "      <td>0.446752</td>\n",
       "      <td>0.667355</td>\n",
       "      <td>0.634916</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.905054  0.830627  0.791032  0.650030  0.726911  0.794661  0.785561   \n",
       "1  0.890581  0.806346  0.780677  0.262780  0.330473  0.798218  0.768104   \n",
       "2  0.816178  0.677894  0.392524  0.529311  0.275011  0.371895  0.020806   \n",
       "3  0.807725  0.576972  0.699284  0.571747  0.646620  0.685664  0.762300   \n",
       "4  0.879808  0.671233  0.591219  0.555190  0.546275  0.640449  0.376038   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.785303  0.416636  0.836273   ...    0.819071  0.687870  0.327691   \n",
       "1  0.638112  0.523704  0.714391   ...    0.558997  0.139567  0.331483   \n",
       "2  0.469636  0.326216  0.557980   ...    0.640669  0.544715  0.014002   \n",
       "3  0.548918  0.586436  0.762267   ...    0.637614  0.574696  0.365580   \n",
       "4  0.399086  0.368852  0.688920   ...    0.854777  0.657088  0.604125   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.770494  0.737494  0.265930  0.677964  0.180462  0.528686       0  \n",
       "1  0.574336  0.149787  0.375146  0.545059  0.539564  0.722114       0  \n",
       "2  0.667235  0.385818 -0.022494  0.495472  0.093924  0.420528       0  \n",
       "3  0.647420  0.596575  0.410199  0.851912  0.704787  0.691468       0  \n",
       "4  0.766604  0.511823  0.446752  0.667355  0.634916  0.733674       0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data = pd.read_csv('fmriprep_BIPOLAR_CONTROL.csv', index_col=0)\n",
    "# mri_data = data[data.columns[:-1]]\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "0    122\n",
      "1     49\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n",
      "(training took 6556.250585079193s)\n",
      "\n",
      "Training LR...\n",
      "(training took 146.55772423744202s)\n",
      "\n",
      "Training RFC...\n",
      "(training took 95.12706732749939s)\n",
      "\n",
      "Training KNN...\n",
      "(training took 2134.7394058704376s)\n",
      "\n",
      "Scoring: roc_auc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 100</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.597208</td>\n",
       "      <td>0.095556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l1, classifier__C = 0.01</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.622848</td>\n",
       "      <td>0.090198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 26, classifier__weights = uniform, classifier__p = 2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.642763</td>\n",
       "      <td>0.081944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__kernel = rbf, classifier__C = 100, classifier__gamma = 0.001</td>\n",
       "      <td>SelectKBest(k=100, score_func=&lt;function f_classif at 0x7f1f267aa510&gt;)</td>\n",
       "      <td>0.620336</td>\n",
       "      <td>0.088884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           best parameters  \\\n",
       "classifier                                                                                   \n",
       "RFC                                                         classifier__n_estimators = 100   \n",
       "LR                                          classifier__penalty = l1, classifier__C = 0.01   \n",
       "KNN         classifier__n_neighbors = 26, classifier__weights = uniform, classifier__p = 2   \n",
       "SVC               classifier__kernel = rbf, classifier__C = 100, classifier__gamma = 0.001   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "RFC         SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "LR                                           PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "KNN                                          PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "SVC                                                                                         SelectKBest(k=100, score_func=<function f_classif at 0x7f1f267aa510>)   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "RFC         0.597208  0.095556  \n",
       "LR          0.622848  0.090198  \n",
       "KNN         0.642763  0.081944  \n",
       "SVC         0.620336  0.088884  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "KNN\n",
      "classifier__n_neighbors = 26\n",
      "classifier__weights = uniform\n",
      "dim_reduction = PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "classifier__p = 2\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_S, grid_cv_svc_mri_S, grid_cv_lr_mri_S, grid_cv_rfc_mri_S, grid_cv_knn_mri_S= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_S, \"fMRI_fmriprep_best_BIPOLAR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 100</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.597208</td>\n",
       "      <td>0.095556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l1, classifier__C = 0.01</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.622848</td>\n",
       "      <td>0.090198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 26, classifier__weights = uniform, classifier__p = 2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.642763</td>\n",
       "      <td>0.081944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__kernel = rbf, classifier__C = 100, classifier__gamma = 0.001</td>\n",
       "      <td>SelectKBest(k=100, score_func=&lt;function f_classif at 0x7f1f267aa510&gt;)</td>\n",
       "      <td>0.620336</td>\n",
       "      <td>0.088884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           best parameters  \\\n",
       "classifier                                                                                   \n",
       "RFC                                                         classifier__n_estimators = 100   \n",
       "LR                                          classifier__penalty = l1, classifier__C = 0.01   \n",
       "KNN         classifier__n_neighbors = 26, classifier__weights = uniform, classifier__p = 2   \n",
       "SVC               classifier__kernel = rbf, classifier__C = 100, classifier__gamma = 0.001   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "RFC         SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "LR                                           PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "KNN                                          PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "SVC                                                                                         SelectKBest(k=100, score_func=<function f_classif at 0x7f1f267aa510>)   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "RFC         0.597208  0.095556  \n",
       "LR          0.622848  0.090198  \n",
       "KNN         0.642763  0.081944  \n",
       "SVC         0.620336  0.088884  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "KNN\n",
      "classifier__n_neighbors = 26\n",
      "classifier__weights = uniform\n",
      "dim_reduction = PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "classifier__p = 2\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_S,\n",
    "        \"LR\" : grid_cv_lr_mri_S,\n",
    "        \"RFC\" : grid_cv_rfc_mri_S,\n",
    "        \"KNN\" : grid_cv_knn_mri_S,\n",
    "                  }, save_plot_to='fmriprep_BIPOLAR_CONTROL.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIPOLAR / control aroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904770</td>\n",
       "      <td>0.829369</td>\n",
       "      <td>0.792125</td>\n",
       "      <td>0.653076</td>\n",
       "      <td>0.728872</td>\n",
       "      <td>0.794980</td>\n",
       "      <td>0.787377</td>\n",
       "      <td>0.787231</td>\n",
       "      <td>0.417565</td>\n",
       "      <td>0.836704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821399</td>\n",
       "      <td>0.687904</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>0.774967</td>\n",
       "      <td>0.733535</td>\n",
       "      <td>0.268768</td>\n",
       "      <td>0.676869</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>0.531821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.806560</td>\n",
       "      <td>0.781289</td>\n",
       "      <td>0.269488</td>\n",
       "      <td>0.334397</td>\n",
       "      <td>0.799294</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.640816</td>\n",
       "      <td>0.525752</td>\n",
       "      <td>0.716471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557017</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>0.336290</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.158645</td>\n",
       "      <td>0.377989</td>\n",
       "      <td>0.548788</td>\n",
       "      <td>0.540977</td>\n",
       "      <td>0.727260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816769</td>\n",
       "      <td>0.677599</td>\n",
       "      <td>0.387493</td>\n",
       "      <td>0.527873</td>\n",
       "      <td>0.265885</td>\n",
       "      <td>0.370717</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.449543</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.559328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646365</td>\n",
       "      <td>0.545378</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.671346</td>\n",
       "      <td>0.385499</td>\n",
       "      <td>-0.010096</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>0.091793</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808305</td>\n",
       "      <td>0.571613</td>\n",
       "      <td>0.700602</td>\n",
       "      <td>0.572765</td>\n",
       "      <td>0.646205</td>\n",
       "      <td>0.686534</td>\n",
       "      <td>0.761346</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>0.588374</td>\n",
       "      <td>0.762286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639721</td>\n",
       "      <td>0.574518</td>\n",
       "      <td>0.368526</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.598606</td>\n",
       "      <td>0.415526</td>\n",
       "      <td>0.851607</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.689314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879478</td>\n",
       "      <td>0.672525</td>\n",
       "      <td>0.591183</td>\n",
       "      <td>0.554872</td>\n",
       "      <td>0.548473</td>\n",
       "      <td>0.641077</td>\n",
       "      <td>0.376989</td>\n",
       "      <td>0.400039</td>\n",
       "      <td>0.367120</td>\n",
       "      <td>0.690383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855391</td>\n",
       "      <td>0.658596</td>\n",
       "      <td>0.602303</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.515096</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>0.670776</td>\n",
       "      <td>0.631877</td>\n",
       "      <td>0.731177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.904770  0.829369  0.792125  0.653076  0.728872  0.794980  0.787377   \n",
       "1  0.891253  0.806560  0.781289  0.269488  0.334397  0.799294  0.768852   \n",
       "2  0.816769  0.677599  0.387493  0.527873  0.265885  0.370717  0.020080   \n",
       "3  0.808305  0.571613  0.700602  0.572765  0.646205  0.686534  0.761346   \n",
       "4  0.879478  0.672525  0.591183  0.554872  0.548473  0.641077  0.376989   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.787231  0.417565  0.836704   ...    0.821399  0.687904  0.328590   \n",
       "1  0.640816  0.525752  0.716471   ...    0.557017  0.146031  0.336290   \n",
       "2  0.449543  0.319015  0.559328   ...    0.646365  0.545378  0.027825   \n",
       "3  0.552699  0.588374  0.762286   ...    0.639721  0.574518  0.368526   \n",
       "4  0.400039  0.367120  0.690383   ...    0.855391  0.658596  0.602303   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.774967  0.733535  0.268768  0.676869  0.178262  0.531821       0  \n",
       "1  0.576098  0.158645  0.377989  0.548788  0.540977  0.727260       0  \n",
       "2  0.671346  0.385499 -0.010096  0.493672  0.091793  0.427800       0  \n",
       "3  0.650250  0.598606  0.415526  0.851607  0.705155  0.689314       0  \n",
       "4  0.766093  0.515096  0.445765  0.670776  0.631877  0.731177       0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data = pd.read_csv('aroma_BIPOLAR_CONTROL.csv', index_col=0)\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "0    122\n",
      "1     49\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n",
      "(training took 9717.726828098297s)\n",
      "\n",
      "Training LR...\n",
      "(training took 166.39950799942017s)\n",
      "\n",
      "Training RFC...\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_aB, grid_cv_svc_mri_aB, grid_cv_lr_mri_aB, grid_cv_rfc_mri_aB, grid_cv_knn_mri_aB= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_aB, \"fMRI_aroma_best_BIPOLAR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 190</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...</td>\n",
       "      <td>0.597278</td>\n",
       "      <td>0.135462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.01</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...</td>\n",
       "      <td>0.630221</td>\n",
       "      <td>0.112358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 29, classifier__weights = distance, classifier__p = 2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.638164</td>\n",
       "      <td>0.090795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__kernel = rbf, classifier__C = 10, classifier__gamma = 0.001</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...</td>\n",
       "      <td>0.645328</td>\n",
       "      <td>0.105587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "RFC                                                          classifier__n_estimators = 190   \n",
       "LR                                           classifier__penalty = l2, classifier__C = 0.01   \n",
       "KNN         classifier__n_neighbors = 29, classifier__weights = distance, classifier__p = 2   \n",
       "SVC                 classifier__kernel = rbf, classifier__C = 10, classifier__gamma = 0.001   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "RFC         SelectNFeaturesFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, ma...   \n",
       "LR          SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...   \n",
       "KNN                                          PCA(copy=True, iterated_power='auto', n_components=10, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "SVC         SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "RFC         0.597278  0.135462  \n",
       "LR          0.630221  0.112358  \n",
       "KNN         0.638164  0.090795  \n",
       "SVC         0.645328  0.105587  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
      "             n_selected=100, prefit=False)\n",
      "classifier__kernel = rbf\n",
      "classifier__C = 10\n",
      "classifier__gamma = 0.001\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_aB,\n",
    "        \"LR\" : grid_cv_lr_mri_aB,\n",
    "        \"RFC\" : grid_cv_rfc_mri_aB,\n",
    "        \"KNN\" : grid_cv_knn_mri_aB,\n",
    "                  }, save_plot_to='aroma_BIPOLAR_CONTROL.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIPOLAR / control openneuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.903161</td>\n",
       "      <td>0.840220</td>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.610086</td>\n",
       "      <td>0.692490</td>\n",
       "      <td>0.802297</td>\n",
       "      <td>0.773570</td>\n",
       "      <td>0.780192</td>\n",
       "      <td>0.368664</td>\n",
       "      <td>0.832882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787642</td>\n",
       "      <td>0.643449</td>\n",
       "      <td>0.338068</td>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.746291</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>0.096085</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909305</td>\n",
       "      <td>0.802791</td>\n",
       "      <td>0.838261</td>\n",
       "      <td>0.043383</td>\n",
       "      <td>0.082807</td>\n",
       "      <td>0.803068</td>\n",
       "      <td>0.809212</td>\n",
       "      <td>0.416151</td>\n",
       "      <td>0.442813</td>\n",
       "      <td>0.780733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.206885</td>\n",
       "      <td>0.176679</td>\n",
       "      <td>0.610826</td>\n",
       "      <td>0.264911</td>\n",
       "      <td>0.138920</td>\n",
       "      <td>0.441210</td>\n",
       "      <td>0.425356</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814521</td>\n",
       "      <td>0.659220</td>\n",
       "      <td>0.405604</td>\n",
       "      <td>0.478532</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>0.053502</td>\n",
       "      <td>0.349824</td>\n",
       "      <td>0.160864</td>\n",
       "      <td>0.540026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536216</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.633059</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.197323</td>\n",
       "      <td>0.480678</td>\n",
       "      <td>0.323474</td>\n",
       "      <td>0.352620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803096</td>\n",
       "      <td>0.623738</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.553537</td>\n",
       "      <td>0.644795</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.774026</td>\n",
       "      <td>0.548577</td>\n",
       "      <td>0.559302</td>\n",
       "      <td>0.758565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607646</td>\n",
       "      <td>0.598106</td>\n",
       "      <td>0.116864</td>\n",
       "      <td>0.620691</td>\n",
       "      <td>0.652045</td>\n",
       "      <td>0.273250</td>\n",
       "      <td>0.801309</td>\n",
       "      <td>0.595647</td>\n",
       "      <td>0.552837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.611540</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>0.521051</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.347330</td>\n",
       "      <td>0.372602</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848746</td>\n",
       "      <td>0.639268</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.689398</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>0.375309</td>\n",
       "      <td>0.683850</td>\n",
       "      <td>0.640729</td>\n",
       "      <td>0.704982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.903161  0.840220  0.799509  0.610086  0.692490  0.802297  0.773570   \n",
       "1  0.909305  0.802791  0.838261  0.043383  0.082807  0.803068  0.809212   \n",
       "2  0.814521  0.659220  0.405604  0.478532  0.200010  0.442241  0.053502   \n",
       "3  0.803096  0.623738  0.697469  0.553537  0.644795  0.679426  0.774026   \n",
       "4  0.875554  0.666578  0.611540  0.528136  0.521051  0.648060  0.388698   \n",
       "\n",
       "          7         8         9   ...        6661      6662      6663  \\\n",
       "0  0.780192  0.368664  0.832882   ...    0.787642  0.643449  0.338068   \n",
       "1  0.416151  0.442813  0.780733   ...    0.616644  0.206885  0.176679   \n",
       "2  0.349824  0.160864  0.540026   ...    0.536216  0.468293  0.037932   \n",
       "3  0.548577  0.559302  0.758565   ...    0.607646  0.598106  0.116864   \n",
       "4  0.347330  0.372602  0.683579   ...    0.848746  0.639268  0.588427   \n",
       "\n",
       "       6664      6665      6666      6667      6668      6669  target  \n",
       "0  0.675770  0.746291  0.280110  0.617764  0.096085  0.509282       0  \n",
       "1  0.610826  0.264911  0.138920  0.441210  0.425356  0.471542       0  \n",
       "2  0.633059  0.294800  0.197323  0.480678  0.323474  0.352620       0  \n",
       "3  0.620691  0.652045  0.273250  0.801309  0.595647  0.552837       0  \n",
       "4  0.689398  0.392779  0.375309  0.683850  0.640729  0.704982       0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data = pd.read_csv('openneuro_BIPOLAR_CONTROL.csv', index_col=0)\n",
    "mri_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: \n",
      "0    122\n",
      "1     49\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Training SVC...\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "X, y = mri_data[mri_data.columns[:-1]], mri_data[mri_data.columns[-1]]\n",
    "\n",
    "best_model_mri_oB, grid_cv_svc_mri_oB, grid_cv_lr_mri_oB, grid_cv_rfc_mri_oB, grid_cv_knn_mri_oB= train_grid_cv(\n",
    "    X, y, n_splits=n_splits, n_repeats=3, scoring=scoring, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_mri_oB, \"fMRI_openneuro_best_BIPOLAR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dim. reduction method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>classifier__n_estimators = 160</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...</td>\n",
       "      <td>0.626461</td>\n",
       "      <td>0.083649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>classifier__penalty = l2, classifier__C = 0.01</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.678421</td>\n",
       "      <td>0.103674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>classifier__n_neighbors = 26, classifier__weights = distance, classifier__p = 2</td>\n",
       "      <td>SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...</td>\n",
       "      <td>0.641399</td>\n",
       "      <td>0.096235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>classifier__kernel = linear, classifier__C = 10, classifier__gamma = 0.001</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)</td>\n",
       "      <td>0.689937</td>\n",
       "      <td>0.104764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            best parameters  \\\n",
       "classifier                                                                                    \n",
       "RFC                                                          classifier__n_estimators = 160   \n",
       "LR                                           classifier__penalty = l2, classifier__C = 0.01   \n",
       "KNN         classifier__n_neighbors = 26, classifier__weights = distance, classifier__p = 2   \n",
       "SVC              classifier__kernel = linear, classifier__C = 10, classifier__gamma = 0.001   \n",
       "\n",
       "                                                                                                                                       best dim. reduction method  \\\n",
       "classifier                                                                                                                                                          \n",
       "RFC         SelectNFeaturesFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_fe...   \n",
       "LR                                           PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "KNN         SelectNFeaturesFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\\n           max_depth=None, max_feat...   \n",
       "SVC                                          PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\\n  svd_solver='auto', tol=0.0, whiten=False)   \n",
       "\n",
       "                mean       std  \n",
       "classifier                      \n",
       "RFC         0.626461  0.083649  \n",
       "LR          0.678421  0.103674  \n",
       "KNN         0.641399  0.096235  \n",
       "SVC         0.689937  0.104764  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "SVC\n",
      "dim_reduction = PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "classifier__kernel = linear\n",
      "classifier__C = 10\n",
      "classifier__gamma = 0.001\n"
     ]
    }
   ],
   "source": [
    "print_results({\n",
    "        \"SVC\" : grid_cv_svc_mri_oB,\n",
    "        \"LR\" : grid_cv_lr_mri_oB,\n",
    "        \"RFC\" : grid_cv_rfc_mri_oB,\n",
    "        \"KNN\" : grid_cv_knn_mri_oB,\n",
    "                  }, save_plot_to='openneuro_BIPOLAR_CONTROL.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
